{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GwiHwan-Go/Reproduce_CutMix/blob/main/Training/feature_cutmix_tinyImagenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLDkuabL0J8U",
        "outputId": "ac623bb0-f134-4500-fb5b-5e8b751ae68c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-21 16:35:25--  http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
            "Resolving cs231n.stanford.edu (cs231n.stanford.edu)... 171.64.68.10\n",
            "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248100043 (237M) [application/zip]\n",
            "Saving to: ‘tiny-imagenet-200.zip’\n",
            "\n",
            "tiny-imagenet-200.z 100%[===================>] 236.61M  18.7MB/s    in 16s     \n",
            "\n",
            "2022-05-21 16:35:42 (14.6 MB/s) - ‘tiny-imagenet-200.zip’ saved [248100043/248100043]\n",
            "\n",
            "test  train  val  wnids.txt  words.txt\n"
          ]
        }
      ],
      "source": [
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
        "!unzip -q tiny-imagenet-200.zip && ls tiny-imagenet-200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-00JulfD0c5x"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import torch\n",
        "\n",
        "training_data_list = []\n",
        "for folder in os.listdir('./tiny-imagenet-200/train/'):\n",
        "  label = folder  # The name of the folder is the label of the images it contains\n",
        "  for file in os.listdir('./tiny-imagenet-200/train/' + folder + '/images/'):\n",
        "    file_dir = './tiny-imagenet-200/train/' + folder + '/images/' + file\n",
        "    training_data_list.append((file_dir, label))\n",
        "with open('./training_data_list.json', 'w') as f:\n",
        "  json.dump(training_data_list, f)\n",
        "\n",
        "testing_data_list = []\n",
        "with open('./tiny-imagenet-200/val/val_annotations.txt', 'r') as f:\n",
        "  for line in f.readlines():\n",
        "    file, label = line.split()[0:2]\n",
        "    file_dir = './tiny-imagenet-200/val/images/' + file\n",
        "    testing_data_list.append((file_dir, label))\n",
        "\n",
        "with open('./testing_data_list.json', 'w') as f:\n",
        "  json.dump(testing_data_list, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erj1tUFDGzIx",
        "outputId": "8780eb6f-a7a9-4926-c88f-d9715d95c9ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "with open('./tiny-imagenet-200/wnids.txt', 'r') as f :\n",
        "  label_id = f.readlines()\n",
        "label_id = [i[:-1] for i in label_id]\n",
        "len(label_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LlBoPbvb05Sf"
      },
      "outputs": [],
      "source": [
        "\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.dataloader import *\n",
        "import cv2 # OpenCV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jllp8PuW06q6"
      },
      "outputs": [],
      "source": [
        "class TinyImageDataset(Dataset):\n",
        "  def __init__ (self, data, transform) :\n",
        "    \n",
        "    self.data = data\n",
        "    self.transform = transform\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img_path, label = self.data[index]\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_COLOR) \n",
        "    if self.transform is not None:\n",
        "      img = self.transform(img)\n",
        "    return img, label_id.index(label)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oRJkzWVU8dyX"
      },
      "outputs": [],
      "source": [
        "file_name='./training_data_list.json'\n",
        "with open(file_name, 'r') as f:\n",
        "  data = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.dataloader import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from tqdm.auto import tqdm, trange\n",
        "import sys, os\n",
        "import cv2 # OpenCV"
      ],
      "metadata": {
        "id": "Yv-ZDrZadXM2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## https://github.com/kuangliu/pytorch-cifar/blob/master/models/resnet.py\n",
        "'''ResNet in PyTorch.\n",
        "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
        "Reference:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "'''\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10, per_img_std = False):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.per_img_std = per_img_std\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, target=None, mixup_hidden = False,  mixup_alpha = 0.1, layer_mix=None):\n",
        "        if self.per_img_std:\n",
        "            x = per_image_standardization(x)\n",
        "        \n",
        "        if mixup_hidden == True:\n",
        "            if layer_mix == None:\n",
        "                layer_mix = random.randint(0,2)\n",
        "            \n",
        "            out = x\n",
        "            \n",
        "            if layer_mix == 0:\n",
        "                #out = lam * out + (1 - lam) * out[index,:]\n",
        "                out, y_a, y_b, lam = cutmix_data(out, target, mixup_alpha)\n",
        "            #print (out)       \n",
        "            \n",
        "            out = F.relu(self.bn1(self.conv1(x)))\n",
        "            \n",
        "            out = self.layer1(out)\n",
        "    \n",
        "            if layer_mix == 1:\n",
        "                #out = lam * out + (1 - lam) * out[index,:]\n",
        "                out, y_a, y_b, lam = cutmix_data(out, target, mixup_alpha)\n",
        "            \n",
        "            #print (out)\n",
        "\n",
        "            out = self.layer2(out)\n",
        "    \n",
        "            if layer_mix == 2:\n",
        "                #out = lam * out + (1 - lam) * out[index,:]\n",
        "                out, y_a, y_b, lam = cutmix_data(out, target, mixup_alpha)\n",
        "           #print (out)\n",
        "\n",
        "            out = self.layer3(out)\n",
        "            \n",
        "            if layer_mix == 3:\n",
        "                #out = lam * out + (1 - lam) * out[index,:]\n",
        "                out, y_a, y_b, lam = cutmix_data(out, target, mixup_alpha)\n",
        "            #print (out)\n",
        "\n",
        "            out = self.layer4(out)\n",
        "            \n",
        "            if layer_mix == 4:\n",
        "                #out = lam * out + (1 - lam) * out[index,:]\n",
        "                out, y_a, y_b, lam = cutmix_data(out, target, mixup_alpha)\n",
        "\n",
        "            #print (out)\n",
        "            out = F.avg_pool2d(out, 4)\n",
        "            out = out.view(out.size(0), -1)\n",
        "            print('in',out.shape)\n",
        "            out = self.linear(out)\n",
        "            print(out.shape)\n",
        "\n",
        "            if layer_mix == 5:\n",
        "                #out = lam * out + (1 - lam) * out[index,:]\n",
        "                out, y_a, y_b, lam = cutmix_data(out, target, mixup_alpha)\n",
        "            \n",
        "            lam = torch.tensor(lam).cuda()\n",
        "            lam = lam.repeat(y_a.size())\n",
        "            #d = {}\n",
        "            #d['out'] = out\n",
        "            #d['target_a'] = y_a\n",
        "            #d['target_b'] = y_b\n",
        "            #d['lam'] = lam\n",
        "            #print (out.shape)\n",
        "            #print (y_a.shape)\n",
        "            #print (y_b.size()) \n",
        "            #print (lam.size())\n",
        "            return out, y_a, y_b, lam\n",
        "\n",
        "        \n",
        "        else:\n",
        "            out = x\n",
        "            out = F.relu(self.bn1(self.conv1(x)))\n",
        "            out = self.layer1(out)\n",
        "            out = self.layer2(out)\n",
        "            out = self.layer3(out)\n",
        "            out = self.layer4(out)\n",
        "            out = F.avg_pool2d(out, 4)\n",
        "            out = out.view(out.size(0), -1)\n",
        "            out = self.linear(out)\n",
        "            return out\n",
        "\n",
        "def per_image_standardization(x):\n",
        "    y = x.view(-1, x.shape[1]*x.shape[2]*x.shape[3])\n",
        "    mean = y.mean(dim=1, keepdim = True).expand_as(y)    \n",
        "    std = y.std(dim=1, keepdim = True).expand_as(y)      \n",
        "    adjusted_std = torch.max(std, 1.0/torch.sqrt(torch.cuda.FloatTensor([x.shape[1]*x.shape[2]*x.shape[3]])))    \n",
        "    y = (y- mean)/ adjusted_std\n",
        "    standarized_input =  y.view(x.shape[0],x.shape[1],x.shape[2],x.shape[3])  \n",
        "    return standarized_input      \n",
        "\n",
        "def resnet18(num_classes=10, dropout = False, per_img_std = False):\n",
        "    \"\"\"Constructs a ResNet-18 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(BasicBlock, [2, 2, 2, 2], num_classes, per_img_std = per_img_std)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet34(num_classes=10, dropout = False, per_img_std = False):\n",
        "    \"\"\"Constructs a ResNet-34 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(BasicBlock, [3, 4, 6, 3], num_classes, per_img_std = per_img_std)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet50(num_classes=10, dropout = False, per_img_std = False):\n",
        "    \"\"\"Constructs a ResNet-50 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 4, 6, 3], num_classes, per_img_std = per_img_std)\n",
        "    return model\n",
        "\n",
        "def cutmix_data(x, y, alpha):\n",
        "\n",
        "    '''Compute the mixup data. Return mixed inputs, pairs of targets, and lambda'''\n",
        "    if alpha > 0.:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1.\n",
        "        \n",
        "    batch_size = x.size()[0]\n",
        "    rand_index = torch.randperm(batch_size).cuda()\n",
        "\n",
        "    W,H = x.size()[2], x.size()[3]\n",
        "\n",
        "    cut_rat = np.sqrt(1. - lam)\n",
        "    cut_w = np.int64(W * cut_rat)\n",
        "    cut_h = np.int64(H * cut_rat)\n",
        "\n",
        "    # uniform\n",
        "    cx = np.random.randint(W)\n",
        "    cy = np.random.randint(H)\n",
        "\n",
        "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
        "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
        "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
        "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
        "\n",
        "    x[:, :, bbx1:bbx2, bby1:bby2] = x[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
        "    y_a, y_b = y, y[rand_index]\n",
        "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (W*H))\n",
        "    return x, y_a, y_b, lam"
      ],
      "metadata": {
        "id": "306ThDDFdYk4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######HYPERPARAMS#########\n",
        "batch_size = 128\n",
        "num_classes = 200\n",
        "num_epochs = 300\n",
        "dropout=0\n",
        "stride = 2\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor()])\n",
        "#######HYPERPARAMS#########"
      ],
      "metadata": {
        "id": "pvQJVly_eE_1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "fMEbjtc41sfl"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_dataset = TinyImageDataset(data = data, transform = transform)\n",
        "train_set, valid_set = train_test_split(train_dataset, test_size=0.2)\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "B5jYc2z_-4WC"
      },
      "outputs": [],
      "source": [
        "model = resnet50(num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].contiguous().view(-1).float().sum(0, keepdim=True)\n",
        "        wrong_k = batch_size - correct_k\n",
        "        res.append(wrong_k.mul_(100.0 / batch_size))\n",
        "    return res\n",
        "    \n",
        "def train_model(model, \n",
        "                train, \n",
        "                valid,\n",
        "                resume = None,\n",
        "                n_iters=300, \n",
        "                learn_rate=0.1, \n",
        "                weight_decay=0, \n",
        "                which_method=0\n",
        "                ):  # Lists to store model's performance information\n",
        "  po = 0\n",
        "  top1_errs, top5_errs = [], []\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  bce_loss = nn.BCELoss().cuda()\n",
        "  softmax = nn.Softmax(dim=1).cuda()\n",
        "  optimizer = optim.SGD(model.parameters(), lr=learn_rate, momentum=0.9, weight_decay=weight_decay)\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')    \n",
        "  print(f\"we are going to use {device}\")\n",
        "###############Checkpoint Zone################\n",
        "  if resume is not None :\n",
        "    checkpoint = torch.load(resume) \n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    loss = checkpoint['loss']\n",
        "    num_epochs = checkpoint['total_epochs'] - checkpoint['epoch']\n",
        "    top1_errs = checkpoint['top1_err']\n",
        "    top5_errs = checkpoint['top5_err']\n",
        "  else :\n",
        "    num_epochs = n_iters\n",
        "###############Checkpoint Zone###############\n",
        "  \n",
        "  print(f\"We still have to go {num_epochs} epochs\" )\n",
        "  for i in trange(num_epochs):\n",
        "\n",
        "    ##############################learning_decay#####################################\n",
        "    if (num_epochs-i) < 75 :\n",
        "      newpo = 3\n",
        "    elif (num_epochs-i) < 150 :\n",
        "      newpo = 2\n",
        "    elif (num_epochs-i) < 225 :\n",
        "      newpo = 1\n",
        "    else :\n",
        "      newpo = 0\n",
        "    if po != newpo :\n",
        "      po = newpo\n",
        "      lr = learn_rate * (0.1 ** po) ##learning_decay\n",
        "      optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
        "    ##############################learning_decay#####################################\n",
        "\n",
        "    try :\n",
        "      for images, labels in tqdm(train) :\n",
        "        \n",
        "        model = model.to(device)\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        model.train()\n",
        "\n",
        "        output, reweighted_target = model(images, labels, mixup_hidden=True, mixup_alpha = 1.0)\n",
        "        loss = bce_loss(softmax(output), reweighted_target) ##??\n",
        "          #############Forward Pass##############\n",
        "\n",
        "        loss.backward()               # backward pass (compute parameter updates)\n",
        "        optimizer.step()              # make the updates for each parameter\n",
        "        optimizer.zero_grad()         # reset the gradients for the next iteration\n",
        "      \n",
        "      #####################model Evaluation#############\n",
        "      model.eval()\n",
        "      sum_top1, sum_top5 = 0,0\n",
        "\n",
        "      for images, labels in valid :\n",
        "        images,labels = images.to(device), labels.to(device)\n",
        "        output = model(images)\n",
        "        top1, top5 = accuracy(output, labels, topk=(1,5))\n",
        "        sum_top1+=top1.item()\n",
        "        sum_top5+=top5.item()\n",
        "\n",
        "      size = len(valid)\n",
        "      #####################model Evaluation#############\n",
        "\n",
        "      ###################save history#####################\n",
        "      top1_errs.append(sum_top1/size)\n",
        "      top5_errs.append(sum_top5/size)\n",
        "      ###################save history#####################\n",
        "\n",
        "      if (i+1) % 10 == 0 :\n",
        "\n",
        "        PATH=f\"./{300-(num_epochs-i)}th_checkpoint.pt\"\n",
        "        torch.save({'total_epochs':num_epochs, 'epoch': i, 'model_state_dict': model.state_dict(), \n",
        "        'optimizer_state_dict': optimizer.state_dict(), 'loss': loss, 'top1_err': top1_errs, 'top5_err': top5_errs }, PATH)\n",
        "        print(f\"Successfully saved untill {i} step in {PATH} with model, optimizer, and loss.\")\n",
        "\n",
        "    except :\n",
        "      PATH=f\"./{300-(num_epochs-i)}th_checkpoint.pt\"\n",
        "      torch.save({'total_epochs':num_epochs, 'epoch': i, 'model_state_dict': model.state_dict(), \n",
        "      'optimizer_state_dict': optimizer.state_dict(), 'loss': loss, 'top1_err': top1_errs, 'top5_err': top5_errs }, PATH)\n",
        "      print(f\"Successfully saved untill {i} step in {PATH} with model, optimizer, and loss.\")\n",
        "      return [top1_errs,top5_errs]\n",
        "\n",
        "  PATH = \"./trained.pt\"\n",
        "  print(\"train finished\")\n",
        "  print(f\"Successfully saved untill {n_iters} step in {PATH} with model, optimizer, and loss.\")\n",
        "  torch.save({'total_epochs':num_epochs, 'epoch': i, 'model_state_dict': model.state_dict(), \n",
        "  'optimizer_state_dict': optimizer.state_dict(), 'loss': loss, 'top1_err': top1_errs, 'top5_err': top5_errs}, PATH)\n",
        "  return [top1_errs,top5_errs]\n"
      ],
      "metadata": {
        "id": "3ivqykycd3aQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704,
          "referenced_widgets": [
            "9cbaed567f2f410897a49233eac2ec61",
            "0f0bf892bd0343d1b7d549aaff9fa098",
            "f9e3da6b97b542e281c8ae1a67ceb441",
            "ef1ef6e7bf3c48b08dab9124d29011bf",
            "378bbd6b0abc404f8ded2ee160634696",
            "d3e083b19f5b46ddb852bfb8fc53e2eb",
            "79fe34ea6bf846b8a4ef175f1450086e",
            "4e19da664e504e8a8f4ff3f54e88e354",
            "7c975fcd79364f82aee7cacee6ab626f",
            "b3d60815636e4ad4a73d08129129f160",
            "9c60edc8a6a84529a6e7087516ca388c",
            "616eb17d615d439e92e5236b11ecc0cc",
            "46432322e33b4f069ab8724b37512b9d",
            "726f0857a3514b6aa5c84b2ffdf9e3a1",
            "b5627254eb184b7689ce68d921a5199c",
            "17118851b4754430ae37425edd23645d",
            "b5638b6a539b494e846b547f3fcec39f",
            "62df8b5e42c6455cab7bfe70d22fbb58",
            "ee8109a48e64450eb28115b919d6b7ef",
            "8453520f820e4968a1f5c8a79a6790c8",
            "5340ca4eb93140c295aa4a59da79c037",
            "36746a6f2a5145efb990d0a83610227e"
          ]
        },
        "id": "l18T9JQjAPKW",
        "outputId": "a73e066e-7c47-4fca-89db-e86497e4fd5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "we are going to use cuda\n",
            "We still have to go 300 epochs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/300 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9cbaed567f2f410897a49233eac2ec61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/625 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "616eb17d615d439e92e5236b11ecc0cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-1d348b00fcdb>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train, valid, resume, n_iters, learn_rate, weight_decay, which_method)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreweighted_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixup_hidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixup_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbce_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreweighted_target\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m##??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-d917063bc0ba>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, target, mixup_hidden, mixup_alpha, layer_mix)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-d917063bc0ba>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    443\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 444\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 11.17 GiB total capacity; 10.36 GiB already allocated; 295.19 MiB free; 10.40 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-b28080b6a127>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m logs = train_model(model, train_loader, valid_loader, n_iters=300, \n\u001b[1;32m      5\u001b[0m                     \u001b[0mlearn_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     weight_decay=0, which_method=1) \n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#which method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-1d348b00fcdb>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train, valid, resume, n_iters, learn_rate, weight_decay, which_method)\u001b[0m\n\u001b[1;32m    106\u001b[0m       \u001b[0mPATH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"./{300-(num_epochs-i)}th_checkpoint.pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m       torch.save({'total_epochs':num_epochs, 'epoch': i, 'model_state_dict': model.state_dict(), \n\u001b[0;32m--> 108\u001b[0;31m       'optimizer_state_dict': optimizer.state_dict(), 'loss': loss, 'top1_err': top1_errs, 'top5_err': top5_errs }, PATH)\n\u001b[0m\u001b[1;32m    109\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Successfully saved untill {i} step in {PATH} with model, optimizer, and loss.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtop1_errs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtop5_errs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'loss' referenced before assignment"
          ]
        }
      ],
      "source": [
        "##You should run this cell ONLY FIRST TIME!!!\n",
        "##Otherwise It will OverWrite your Checkpoint file.\n",
        "\n",
        "logs = train_model(model, train_loader, valid_loader, n_iters=300, \n",
        "                    learn_rate=0.1, \n",
        "                    weight_decay=0, which_method=1) \n",
        "\n",
        "#which method \n",
        "# 0: nothing, \n",
        "# 1: cutmix, \n",
        "# 2: mixup \n",
        "# 3: cutout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWpbbrp-dG9j",
        "outputId": "bde50912-c9ea-4a8a-8119-832564330bc6",
        "colab": {
          "referenced_widgets": [
            "65d1d781caf241d69e9a7aeadf6bb917",
            "cec4169e1e8e43079741bcdb865e7e0d"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65d1d781caf241d69e9a7aeadf6bb917",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cec4169e1e8e43079741bcdb865e7e0d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=313), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully saved untill 0 step in ./checkpoint.pt with model, optimizer, and loss.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Chek point load 요령 ##\n",
        "PATH=\"_\" ## Where checkpoint saved. ## saved checkpoint\n",
        "\n",
        "train_model(model,\n",
        "            train_loader, \n",
        "            valid_loader,\n",
        "            n_iters=300, \n",
        "            learn_rate=0.1, \n",
        "            resume=PATH,\n",
        "            weight_decay=0, \n",
        "            which_method=1) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxSANERbdG9k"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOfWiOKhdG9l"
      },
      "outputs": [],
      "source": [
        "## If train was succeed, let's evaluate it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gP1xVtp9dG9l",
        "outputId": "8543015c-bed7-45a0-cb14-40a43912fc36"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2095527dbd38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mPATH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./trained.pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msum_top1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_top5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "PATH=\"./trained.pt\"\n",
        "checkpoint = torch.load(PATH) \n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "sum_top1, sum_top5 = 0,0\n",
        "\n",
        "for images, labels in valid_loader :\n",
        "    images,labels = images.to(device), labels.to(device)\n",
        "    output = model(images)\n",
        "    top1, top5 = accuracy(output, labels, topk=(1,5))\n",
        "    sum_top1+=top1.item()\n",
        "    sum_top5+=top5.item()\n",
        "\n",
        "size = len(valid_loader)\n",
        "\n",
        "print(sum_top1/size, sum_top5/size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHa6IB-JdG9m",
        "outputId": "294dddaf-37fc-456f-d0e1-4ea5fa0d24c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[39.275, 38.73]"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoint['top1_err']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjIZkMAc2ip0"
      },
      "source": [
        "https://github.com/facebookresearch/mixup-cifar10/blob/main/train.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "feature_cutmix_tinyImagenet.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "61a57a4b5406d2de388e2f91097d4e4bcd7d5f4a46f53a795aa28a02eed27fc5"
    },
    "kernelspec": {
      "display_name": "Python 3.7.4 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9cbaed567f2f410897a49233eac2ec61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f0bf892bd0343d1b7d549aaff9fa098",
              "IPY_MODEL_f9e3da6b97b542e281c8ae1a67ceb441",
              "IPY_MODEL_ef1ef6e7bf3c48b08dab9124d29011bf"
            ],
            "layout": "IPY_MODEL_378bbd6b0abc404f8ded2ee160634696"
          }
        },
        "0f0bf892bd0343d1b7d549aaff9fa098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3e083b19f5b46ddb852bfb8fc53e2eb",
            "placeholder": "​",
            "style": "IPY_MODEL_79fe34ea6bf846b8a4ef175f1450086e",
            "value": "  0%"
          }
        },
        "f9e3da6b97b542e281c8ae1a67ceb441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e19da664e504e8a8f4ff3f54e88e354",
            "max": 300,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c975fcd79364f82aee7cacee6ab626f",
            "value": 0
          }
        },
        "ef1ef6e7bf3c48b08dab9124d29011bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3d60815636e4ad4a73d08129129f160",
            "placeholder": "​",
            "style": "IPY_MODEL_9c60edc8a6a84529a6e7087516ca388c",
            "value": " 0/300 [00:00&lt;?, ?it/s]"
          }
        },
        "378bbd6b0abc404f8ded2ee160634696": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3e083b19f5b46ddb852bfb8fc53e2eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79fe34ea6bf846b8a4ef175f1450086e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e19da664e504e8a8f4ff3f54e88e354": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c975fcd79364f82aee7cacee6ab626f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3d60815636e4ad4a73d08129129f160": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c60edc8a6a84529a6e7087516ca388c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "616eb17d615d439e92e5236b11ecc0cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46432322e33b4f069ab8724b37512b9d",
              "IPY_MODEL_726f0857a3514b6aa5c84b2ffdf9e3a1",
              "IPY_MODEL_b5627254eb184b7689ce68d921a5199c"
            ],
            "layout": "IPY_MODEL_17118851b4754430ae37425edd23645d"
          }
        },
        "46432322e33b4f069ab8724b37512b9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5638b6a539b494e846b547f3fcec39f",
            "placeholder": "​",
            "style": "IPY_MODEL_62df8b5e42c6455cab7bfe70d22fbb58",
            "value": "  0%"
          }
        },
        "726f0857a3514b6aa5c84b2ffdf9e3a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee8109a48e64450eb28115b919d6b7ef",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8453520f820e4968a1f5c8a79a6790c8",
            "value": 0
          }
        },
        "b5627254eb184b7689ce68d921a5199c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5340ca4eb93140c295aa4a59da79c037",
            "placeholder": "​",
            "style": "IPY_MODEL_36746a6f2a5145efb990d0a83610227e",
            "value": " 0/625 [00:00&lt;?, ?it/s]"
          }
        },
        "17118851b4754430ae37425edd23645d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5638b6a539b494e846b547f3fcec39f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62df8b5e42c6455cab7bfe70d22fbb58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee8109a48e64450eb28115b919d6b7ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8453520f820e4968a1f5c8a79a6790c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5340ca4eb93140c295aa4a59da79c037": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36746a6f2a5145efb990d0a83610227e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}